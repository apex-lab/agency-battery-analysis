{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebe1681-7662-4eb8-b7fc-7bc175a6d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "from scipy.stats import pearsonr\n",
    "from bids import BIDSLayout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from util.tasks import SoPA_loadings, SoNA_loadings\n",
    "loadings = np.stack([SoPA_loadings, SoNA_loadings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5f8950-952f-4e71-b50a-b3c71846054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout('data_bids_anon', validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9055dbe7-d56f-4e0f-a4a1-d17dcb5c99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sub(sub):\n",
    "    f = layout.get(subject = sub, task = 'SoAScale')[0]\n",
    "    df = f.get_df()\n",
    "    # exclude if only replied 1 or 7\n",
    "    if df.response.isin([1, 7]).all():\n",
    "        exclude = True\n",
    "    elif (df.response[0] == df.response).all(): # or always said same thing\n",
    "        exclude = True\n",
    "    else:\n",
    "        exclude = False\n",
    "    return df.response.to_numpy(), exclude\n",
    "\n",
    "subs = layout.get_subjects(task = 'SoAScale')\n",
    "data = [load_sub(s) for s in subs]\n",
    "X, exclude = list(zip(*data))\n",
    "X, exclude = np.stack(X), np.array(exclude)\n",
    "X = X[~exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9da34de-e2f8-4616-91fd-4fd1713b6a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7388275 , 0.76243121, 0.78281459, 0.613707  , 0.67906274,\n",
       "       0.74147223, 0.74148276, 0.6902449 , 0.66263242, 0.68360632,\n",
       "       0.72146164, 0.57357142, 0.61639507])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_loadings(X, loadings, zero_out = None):\n",
    "    '''\n",
    "    computes the correlation between features and their \n",
    "    expected values given the factor loadings \n",
    "    '''\n",
    "    X = X.copy()\n",
    "    factors = X @ loadings.T # project observations onto factors\n",
    "    if not zero_out is None:\n",
    "        factors[:, zero_out] = factors[:, zero_out].mean()\n",
    "    X_recon = factors @ loadings # project factors back to data\n",
    "    corr = [pearsonr(X[:,j], X_recon[:,j]).statistic for j in range(X.shape[1])]\n",
    "    return np.array(corr)\n",
    "\n",
    "score_loadings(X, loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14078793-638c-4ba3-bf10-752542c5d16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_features(X, seed = None):\n",
    "    '''\n",
    "    Shuffles each column of X individually to generate a draw \n",
    "    from the same randomization null used in \"parallel analysis\" [1] \n",
    "    evaluating factor structures. This idea is that by shuffling\n",
    "    each of the features individually, you destroy the factor \n",
    "    structure while preserving the mean and noise properties of\n",
    "    the features.\n",
    "\n",
    "    References\n",
    "    -------------\n",
    "    [1] Dobriban, E. (2020). Permutation methods for factor analysis and PCA.\n",
    "    '''\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = X.copy()\n",
    "    for i in range(X.shape[1]):\n",
    "        rng.shuffle(X[:,i])\n",
    "    return X\n",
    "\n",
    "shuffle_features(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f5be42-eb85-4f81-a28f-776f3b4f2a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items related to factor structure:\n",
      "\n",
      "Item 3 (r = 0.783, p = 0.008): My actions just happen without my intention\n",
      "Item 7 (r = 0.740, p = 0.050): The outcomes of my actions generally surprise me\n",
      "Item 10 (r = 0.694, p = 0.024): Nothing I do is actually voluntary\n",
      "Item 11 (r = 0.745, p = 0.045): While I am in action, I feel like I am a remote controlled robot\n",
      "\n",
      "Items possibly unrelated to factor structure:\n",
      "\n",
      "Item 1 (r = 0.523, p = 0.116): I am in full control of what I do\n",
      "Item 2 (r = 0.743, p = 0.059): I am just an instrument in the hands of somebody or something else\n",
      "Item 4 (r = 0.460, p = 0.113): I am the author of my actions\n",
      "Item 5 (r = 0.687, p = 0.185): The consequences of my actions feel like they don't logically follow my actions\n",
      "Item 6 (r = 0.719, p = 0.389): My movements are automatic-- my body simply makes them\n",
      "Item 8 (r = -0.277, p = 0.975): Things I do are subjects only to my free will\n",
      "Item 9 (r = 0.455, p = 0.119): The decision whether and when to act is within my hands\n",
      "Item 12 (r = -0.019, p = 0.648): My behavior is planned by me from the very beginning to the very end\n",
      "Item 13 (r = 0.264, p = 0.366): I am completely responsible for everything that results from my actions\n",
      "\n",
      "p = 0.00100 for whole factor model\n"
     ]
    }
   ],
   "source": [
    "def test_factor(exclude_factor):\n",
    "\n",
    "    ## permutation-based confirmatory factor analysis \n",
    "    # score a priori (out-of-sample) loadings\n",
    "    score = score_loadings(X, loadings, exclude_factor)\n",
    "    H0 = [score]\n",
    "    for i in range(1000):\n",
    "        # then compute loadings estimated in-sample but on shuffled data\n",
    "        fa = FactorAnalysis(n_components = 2, rotation = 'quartimax', random_state = i)\n",
    "        Y = shuffle_features(X, seed = i)\n",
    "        fa = fa.fit(Y) # fit new loadings to shuffled features\n",
    "        H0.append(score_loadings(X, fa.components_, exclude_factor)) # and score on unshuffled\n",
    "    H0 = np.stack(H0)\n",
    "    p = (H0 > score).mean(0)\n",
    "\n",
    "    print('Items related to factor structure:\\n')\n",
    "    res = layout.get(task = 'SoAScale')[0].get_df().question[p <= .05]\n",
    "    for item, quest, r, _p in zip(res.index + 1, res, score[p <= .05], p[p <= .05]):\n",
    "        print('Item %d (r = %.03f, p = %.03f): %s'%(item, r, _p, quest))\n",
    "    print('\\nItems possibly unrelated to factor structure:\\n')\n",
    "    res = layout.get(task = 'SoAScale')[0].get_df().question[p > .05]\n",
    "    for item, quest, r, _p in zip(res.index + 1, res, score[p > .05], p[p > .05]):\n",
    "        print('Item %d (r = %.03f, p = %.03f): %s'%(item, r, _p, quest))\n",
    "    p_all = (H0.mean(1) >= score.mean()).mean()\n",
    "    print('\\np = %.05f for whole factor model'%p_all)\n",
    "\n",
    "## sense of negative agency\n",
    "test_factor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55025ea0-8e71-4f46-b96d-73fbae30e034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items related to factor structure:\n",
      "\n",
      "Item 1 (r = 0.727, p = 0.000): I am in full control of what I do\n",
      "Item 2 (r = 0.550, p = 0.005): I am just an instrument in the hands of somebody or something else\n",
      "Item 4 (r = 0.624, p = 0.000): I am the author of my actions\n",
      "Item 5 (r = 0.453, p = 0.007): The consequences of my actions feel like they don't logically follow my actions\n",
      "Item 8 (r = 0.681, p = 0.003): Things I do are subjects only to my free will\n",
      "Item 9 (r = 0.665, p = 0.001): The decision whether and when to act is within my hands\n",
      "Item 10 (r = 0.320, p = 0.008): Nothing I do is actually voluntary\n",
      "Item 11 (r = 0.297, p = 0.011): While I am in action, I feel like I am a remote controlled robot\n",
      "Item 13 (r = 0.625, p = 0.000): I am completely responsible for everything that results from my actions\n",
      "\n",
      "Items possibly unrelated to factor structure:\n",
      "\n",
      "Item 3 (r = -0.452, p = 0.999): My actions just happen without my intention\n",
      "Item 6 (r = -0.232, p = 0.998): My movements are automatic-- my body simply makes them\n",
      "Item 7 (r = -0.281, p = 0.994): The outcomes of my actions generally surprise me\n",
      "Item 12 (r = 0.563, p = 0.987): My behavior is planned by me from the very beginning to the very end\n",
      "\n",
      "p = 0.00200 for whole factor model\n"
     ]
    }
   ],
   "source": [
    "## sense of positive agency\n",
    "test_factor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ec61c5-4c83-4712-8663-a8e05debbb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive agency:\n",
      "------------------\n",
      "Item 1: shapley = 0.566\n",
      "Item 2: shapley = 0.241\n",
      "Item 3: shapley = 0.008\n",
      "Item 4: shapley = 0.329\n",
      "Item 5: shapley = 0.318\n",
      "Item 6: shapley = 0.218\n",
      "Item 7: shapley = 0.011\n",
      "Item 8: shapley = 0.847\n",
      "Item 9: shapley = 0.408\n",
      "Item 10: shapley = 0.078\n",
      "Item 11: shapley = 0.115\n",
      "Item 12: shapley = 1.021\n",
      "Item 13: shapley = 0.512\n",
      "\n",
      "Negative agency:\n",
      "------------------\n",
      "Item 1: shapley = 0.060\n",
      "Item 2: shapley = 0.483\n",
      "Item 3: shapley = 0.543\n",
      "Item 4: shapley = 0.291\n",
      "Item 5: shapley = 0.465\n",
      "Item 6: shapley = 0.886\n",
      "Item 7: shapley = 0.611\n",
      "Item 8: shapley = 0.127\n",
      "Item 9: shapley = 0.193\n",
      "Item 10: shapley = 0.492\n",
      "Item 11: shapley = 0.544\n",
      "Item 12: shapley = 0.032\n",
      "Item 13: shapley = 0.040\n"
     ]
    }
   ],
   "source": [
    "from shap import LinearExplainer\n",
    "from shap.maskers import Partition\n",
    "np.random.seed(0)\n",
    "\n",
    "## estimate Shapley values to quantify impact of features on factor values\n",
    "# (I like this approach but I'm not sure anyone else using psychometric \n",
    "# scales knows what it is so)\n",
    "\n",
    "explainer = LinearExplainer((loadings[0], 0), masker = Partition(X))\n",
    "shap = explainer.shap_values(X)\n",
    "shap = np.abs(shap).mean(0)\n",
    "print('Positive agency:')\n",
    "print('------------------')\n",
    "for item, s in zip(np.arange(1, shap.size + 1), shap):\n",
    "    print('Item %d: shapley = %.03f'%(item, s))\n",
    "\n",
    "explainer = LinearExplainer((loadings[1], 0), masker = Partition(X))\n",
    "shap = explainer.shap_values(X)\n",
    "shap = np.abs(shap).mean(0)\n",
    "print('\\nNegative agency:')\n",
    "print('------------------')\n",
    "for item, s in zip(np.arange(1, shap.size + 1), shap):\n",
    "    print('Item %d: shapley = %.03f'%(item, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf6314-464a-4ad0-b831-48a704d0312f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
